{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "import pprint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .csv:\n",
      "                                         id  label\n",
      "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
      "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
      "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
      "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
      "4  068aba587a4950175d04c680d38943fd488d6a9d      0\n",
      "                                         id  label\n",
      "0  0b2ea2a822ad23fdb1b5dd26653da899fbd2c0d5      0\n",
      "1  95596b92e5066c5c52466c90b69ff089b39f2737      0\n",
      "2  248e6738860e2ebcf6258cdc1f32f299e0c76914      0\n",
      "3  2c35657e312966e9294eac6841726ff3a748febf      0\n",
      "4  145782eb7caa1c516acbe2eda34d9a3f31c41fd6      0\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "imgHeight, imgWidth = 96, 96\n",
    "trainDir = \"./train/\"\n",
    "testDir = \"./test/\"\n",
    "BATCHSIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "# open csv\n",
    "train_df = pd.read_csv(\"train_labels.csv\")\n",
    "test_df = pd.read_csv(\"sample_submission.csv\")\n",
    "print('Loading .csv:')\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files #: 220025\n",
      "Evaluation files #: 57458\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "labeled_files = glob(trainDir +'*.tif')\n",
    "test_files = glob(testDir + '*.tif')\n",
    "\n",
    "print(\"Train files #: {}\".format(len(labeled_files)))\n",
    "print(\"Evaluation files #: {}\".format(len(test_files)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating architecture..\n",
      "[INFO] architecture created..\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# initializing architecture\n",
    "print(\"[INFO] creating architecture..\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(imgWidth, imgHeight, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    " \n",
    "model.compile(loss='binary_crossentropy',\n",
    "               optimizer=opt,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] architecture created..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train generator..\n",
      "Found 220025 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# training data generator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    shear_range=15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    )\n",
    "\n",
    "print(\"[INFO] train generator..\")\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                directory=trainDir,\n",
    "                                                x_col='id',\n",
    "                                                y_col='label',\n",
    "                                                has_ext=False,\n",
    "                                                class_mode='binary',\n",
    "                                                target_size=(imgHeight,imgWidth),\n",
    "                                                batch_size=BATCHSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test generator\n",
      "Found 57458 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] test generator\")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                                 directory=testDir,\n",
    "                                                 x_col='id',\n",
    "                                                 y_col='label',\n",
    "                                                 has_ext=False,\n",
    "                                                 #class_mode='binary',\n",
    "                                                 target_size=(imgHeight,imgWidth),\n",
    "                                                 batch_size=BATCHSIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6875/6875 [==============================] - 2881s 419ms/step - loss: 0.4327 - acc: 0.8063 - val_loss: 2.1092 - val_acc: 0.2526\n",
      "Epoch 2/5\n",
      "6875/6875 [==============================] - 2865s 417ms/step - loss: 0.3672 - acc: 0.8418 - val_loss: 2.1734 - val_acc: 0.2113\n",
      "Epoch 3/5\n",
      "6875/6875 [==============================] - 2857s 416ms/step - loss: 0.3419 - acc: 0.8545 - val_loss: 1.8620 - val_acc: 0.3017\n",
      "Epoch 4/5\n",
      "6875/6875 [==============================] - 2865s 417ms/step - loss: 0.3228 - acc: 0.8646 - val_loss: 2.0991 - val_acc: 0.2671\n",
      "Epoch 5/5\n",
      "6875/6875 [==============================] - 2861s 416ms/step - loss: 0.3093 - acc: 0.8713 - val_loss: 2.5274 - val_acc: 0.2564\n"
     ]
    }
   ],
   "source": [
    "# compiling model\n",
    "H = model.fit_generator(train_generator,\n",
    "                        validation_data=test_generator,\n",
    "                        validation_steps=int(test_generator.n//BATCHSIZE),\n",
    "                        steps_per_epoch=int(train_generator.n//BATCHSIZE),\n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict generator\n",
    "pred_gen = model.predict_generator(test_generator,steps=len(test_generator))\n",
    "#print(pred_gen)\n",
    "print(H.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "print(\"[INFO] saving model...\")\n",
    "\n",
    "model.save('model.model')        \n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to dataframe and output as .csv\n",
    "ids = test_df.id.values\n",
    "preds = [item[0] for item in pred_gen]\n",
    "print(len(ids) == len(preds))\n",
    "df = pd.DataFrame({'id': ids, 'label' : preds})\n",
    "df.to_csv('submit_predictions.csv', index = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Cancer challenge\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('plotCombined.png')\n",
    "\n",
    "\n",
    "#----------------------\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(H.history['acc'])\n",
    "plt.plot(H.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('plot_acc_valacc.png')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(H.history['loss'])\n",
    "plt.plot(H.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('plot_loss_valloss.png')\n",
    "#----------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
